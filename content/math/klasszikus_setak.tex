\chapter{Classical random walks}

A classical random walk describes a stohastic process.

\unsure{The sequence can also be regarded as a special category of Markov chain ->Homogenous?}

Classical random walks on graphs can be defined using Markov-chains. Markov-chains
are well explained in \cite{BreimanProbability} and in \cite{XiaReview}.

\change{Breiman egy könyv, de a Xia cikkben jobban le van írva.}

(Információelmélet előadás / a könyvet be lehetne idézni, bár kevésbé szeretik)

\definition{\textbf{Markov-chain}} (First order, discrete-time, discrete-space) A Markov-chain is a sequence of independent random variables from the same distribution, $X_1, X_2, X_3, \dots$, (with value set $A$), that have the Markov property:

\unsure{Hogy kellene az értékkészletet ($A$) jelölni?}

$P(X_k = x_k | X_{k-1} = x_{k-1}, \dots, X_1 = x_1) = P(X_k = x_k | X_{k-1} = x_{k-1})$

$\forall k\geq{}2$ and $x_{1},\dots, x{k}$ from the value set.

\definition{\textbf{Homogenous Markov-chain}} Time invariant, i.e.:
$P(\Phi_k = i | \Phi_{k-1} = j) = p_{j,i}$ $\forall k\geq{}2$, $\forall i,j \in{} A$, which is called the transition probability from $i$ to $j$ and form the transition probability matrix $P$.

This allows us to represent Homogenous Markov-chains as directed graphs.

\definition{\textbf{Distribution of the Markov-chain}} at the $i$th step, the Markov-chain's distribution is the distribution of $X_i$, which is $P(X_i = j)$.

\definition{\textbf{Stationary distribution}} of the Markov chain is $\pi_{j} = \lim\limits_{i \to \infty} P(X_i = j)$, or where $P\pi = \pi$.
\change{Keep one of the definitions?}

\definition{\textbf{Graph representation of homogenous Markov-chains}}
Graph $G(V,E)$ represents a homogenous Markov-chain $X_1, X_2, X_3, \dots$, (with value set $A$ and transition probability matrix $P$), if $V=A$ and if $p_{j,i} \neq{} 0$, then $E(i,j) = p_{j,i}$ $\forall{}i,j\in{}A$. If $p_{j,i} = 0$, then there is no edge between vertex $i$ and $j$.

\definition{\textbf{Random walk on a graph}}
A random walk on this graph $G$ visits the nodes represented by the Markov-chain: $X_1, X_2, X_3, \dots$. The first node is the start vertex ($X_1$). In the $k$th step we move from vertex $X_k=i$ to vertex $X_{k+1}=j$, with probability $p_{j,i}$.

Important properties for random walks are Hitting time and Mixing time. Hitting time describes how quickly can a vertex be reached from another vertex in the graph and Mixing time how fast the stationary distribution is reached (where we can no longer tell which vertex was the walk started in). Both of these measures will come up later in the analysis of the quantum walks.

\definition{\textbf{Hitting time}} $h_{j,i}$ is the expected number of steps before node $j$ is visited in a random walk starting from node $i$.

Recursively:
\begin{align}
    h_{j,i} = \left\{
        \begin{array}{lr}
            1 + \sum\limits_{k\in{}A}p_{j,k}h_{k,i} & \text{if } i\neq{}j\\
            0 & \text{if} i=j
        \end{array}
    \right.
\end{align}

From \cite{KempeIntroduction} (35, 36):

\definition{\textbf{Mixing time}}: The smallest time index of the Markov chain, where the total variational distance between the current and the stationary distribution is not greater than $\epsilon$.

\begin{align}
m = \min\{T | \forall{}t\geq{}T, \sum\limits_{j}|P(X_t = j) - \pi_j| \leq \epsilon\}
\end{align}

\change{Should I define graphs too?}

\definition{\textbf{Maximum degree of a graph}} the maximum number of outgoing edges from a vertex is the maximum degree of a graph, for graph $G$, it is denoted as $\Delta(G)$.

\definition{\textbf{Graph regularity}} We call a directed graph d-regular if all vertexes have d outgoing edges.